nohup: ignoring input
2023-05-17 16:03:57,144	INFO worker.py:1518 -- Started a local Ray instance.
2023-05-17 16:03:58,030	INFO algorithm.py:354 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
/data1/yxn/anaconda3/envs/torch37/lib/python3.7/site-packages/ray/_private/ray_option_utils.py:273: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/releases-2.0.0/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.
  stacklevel=1,
2023-05-17 16:04:00,931	WARNING catalog.py:642 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
2023-05-17 16:04:00,944	WARNING util.py:65 -- Install gputil for GPU system monitoring.
current_path /data1/yxn/group-intelligence-system/example/cloudManufacturing_network/rl
sys.path ['/data1/yxn/anaconda3/envs/torch37/lib/python3.7/site-packages/ray/thirdparty_files', '/data1/yxn/anaconda3/envs/torch37/lib/python3.7/site-packages/ray/pickle5_files', '/data1/yxn/group-intelligence-system/example/cloudManufacturing_network/rl', '/data1/yxn/group-intelligence-system', '/data1/yxn/anaconda3/envs/torch37/lib/python37.zip', '/data1/yxn/anaconda3/envs/torch37/lib/python3.7', '/data1/yxn/anaconda3/envs/torch37/lib/python3.7/lib-dynload', '/data1/yxn/anaconda3/envs/torch37/lib/python3.7/site-packages', '/data1/yxn/group-intelligence-system/example/cloudManufacturing_network/rl', '/data1/yxn/group-intelligence-system/example/cloudManufacturing_network/rl']
本轮订单已经生成,step: 0
ckpt rl\phase\ckpts\checkpoint_000008
Traceback (most recent call last):
  File "example/cloudManufacturing_network/rl/doTrain.py", line 105, in <module>
    ) = set_up_dirs_and_maybe_restore(run_dir, run_config, trainer)
  File "/data1/yxn/group-intelligence-system/example/cloudManufacturing_network/rl/utils/saving_and_loading.py", line 267, in set_up_dirs_and_maybe_restore
    trainer=trainer_obj, run_dir=run_directory, ckpt=run_configuration["general"].get("ckpt_path", "")
  File "/data1/yxn/group-intelligence-system/example/cloudManufacturing_network/rl/utils/saving_and_loading.py", line 183, in load_snapshot
    trainer.restore(ckpt)
  File "/data1/yxn/anaconda3/envs/torch37/lib/python3.7/site-packages/ray/tune/trainable/trainable.py", line 632, in restore
    f"Could not recover from checkpoint as it does not exist on local "
ValueError: Could not recover from checkpoint as it does not exist on local disk and was not available on cloud storage or another Ray node. Got checkpoint path: rl\phase\ckpts\checkpoint_000008 and IP None
